{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l7kS2wxjCbD-"
   },
   "source": [
    "Best way to study is :\n",
    "--\n",
    "1. Watch the **Self Learning Video** before the session.\n",
    "2. Run codes along with the traner/SME in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jXfEGGEGC63m"
   },
   "source": [
    "ML Process flow or ML Pipeline\n",
    "--\n",
    "![basic_ML_process_flow](https://drive.google.com/uc?id=1mf5Rpq68x9AzyHMAo6xsQ9fVNDbuI4Q3 'basic_ML_process_flow')\n",
    "\n",
    "`Recall, this is where we stopped in our first NB` <br>\n",
    "1. **Data Collection**: Collect the data that the algorithm will learn from.\n",
    "\n",
    "2. **Data Preparation**: Format and engineer the data into the optimal format, extracting important features and performing dimensionality reduction. (*dimensionality reduction means when their are too many features i.e too many columns in our dataset then we need to choose few from all*)\n",
    "\n",
    "3. **Training**: Also known as the fitting stage, this is where the Machine Learning algorithm actually learns by showing it the data that has been collected and prepared.\n",
    "\n",
    "4. **Evaluation**: Test the model to see how well it performs.\n",
    "\n",
    "5. **Tuning**: Fine tune the model to maximise it’s performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nrMzFkE8DLGr"
   },
   "source": [
    "<font color='green'> <b>\n",
    "ML Pipeline is nothing but the steps you follow to clean, pre-process the data, scale or normalise it before training and testing it. \n",
    "</b></font>\n",
    "\n",
    "**`Exprienced ML Engineers`** infact make ML pipeline rigth from Preparing data to Deploying the ML model. ( see diagram below )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgkaHV4GDgd4"
   },
   "source": [
    "![Board_ML_Pipeline](https://drive.google.com/uc?id=1zEz0CfrYofJrYqD-MjGlwj6tzgyhxjVm 'Board_ML_Pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ad0OilDnH9MB"
   },
   "source": [
    "Here we would dive into solving a end-to-end ML problem - **Student Grant Recommendation**;  ofcourse a very simple problem so that you get the feel of **`ML pipeline`.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P091kIpDHfi7"
   },
   "source": [
    "# Objective : Student Grant Recommendation\n",
    "\n",
    "You have historical student performance data and their grant recommendation outcomes in the form of a comma separated value file named student_records.csv. Each data sample consists of the following attributes.\n",
    "\n",
    "• Name (the student name) <br>\n",
    "• OverallGrade (overall grade obtained) <br>\n",
    "• Obedient (whether they were diligent during their course of stay) <br>\n",
    "• ResearchScore (marks obtained in their research work) <br>\n",
    "• ProjectScore (marks obtained in the project) <br>\n",
    "• Recommend (whether they got the grant recommendation) <br>\n",
    "\n",
    "Your main objective is to build a predictive model based on this data such that you can predict for any future student whether they will be recommended for the grant based on their performance attributes.\n",
    "\n",
    "`Note` : This is a <u>toy dataset</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nG0WxGBJJUQp"
   },
   "source": [
    "**`Step 1: Data Retrieval`** <br>\n",
    "Here, we will leverage the pandas framework to retrieve the data from the CSV file. The following snippet shows us how to retrieve the data and view it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "9CkflUbrKCT2",
    "outputId": "dedb9aeb-3786-4463-cef0-5fe1ed2fb7ef"
   },
   "outputs": [],
   "source": [
    "# download the dataset from this link https://drive.google.com/open?id=1viCNZx1e3Egi7zsh72zwGjrA_W8dcpul \n",
    "## if running in colab\n",
    "# then upload this NB to your Colab by running the below code and selecting the .csv file. \n",
    "\n",
    "# loading the dataset into this Colab NB\n",
    "#from google.colab import files\n",
    "#files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "zyEg7WKaJnvG",
    "outputId": "6ad912fb-ab33-463a-b868-0d07e9ceaf3c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>OverallGrade</th>\n",
       "      <th>Obedient</th>\n",
       "      <th>ResearchScore</th>\n",
       "      <th>ProjectScore</th>\n",
       "      <th>Recommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Henry</td>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>90</td>\n",
       "      <td>85</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "      <td>85</td>\n",
       "      <td>51</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Holmes</td>\n",
       "      <td>B</td>\n",
       "      <td>Y</td>\n",
       "      <td>75</td>\n",
       "      <td>71</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Marvin</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Simon</td>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>92</td>\n",
       "      <td>79</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Robert</td>\n",
       "      <td>B</td>\n",
       "      <td>Y</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Trent</td>\n",
       "      <td>C</td>\n",
       "      <td>Y</td>\n",
       "      <td>75</td>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name OverallGrade Obedient  ResearchScore  ProjectScore Recommend\n",
       "0   Henry            A        Y             90            85       Yes\n",
       "1    John            C        N             85            51       Yes\n",
       "2   David            F        N             10            17        No\n",
       "3  Holmes            B        Y             75            71        No\n",
       "4  Marvin            E        N             20            30        No\n",
       "5   Simon            A        Y             92            79       Yes\n",
       "6  Robert            B        Y             60            59        No\n",
       "7   Trent            C        Y             75            33        No"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#--get data into a DataFrame\n",
    "import pandas as pd\n",
    "df = pd.read_csv('student_records.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SxP3RajlLt6M"
   },
   "source": [
    "**`Step 2: Data Preparation`**<br>\n",
    "Based on the dataset (above), we do not have any data errors or missing values, hence we will mainly focus on feature engineering and scaling in this NB.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1pZX9qjyZerJ"
   },
   "source": [
    "**`Step 3 : Feature Extraction and Engineering`** <br>\n",
    "Let’s start by extracting the existing features from the dataset and the outcomes; in separate variables.\n",
    "\n",
    "`Note 1` : Features are input variables on which the ML model would be trained. They are always represented as X.\n",
    "\n",
    "`Note 2` : The only column which is not in the set of features would be the Outcome or label. Outcome or Label when available helps the ML model to map features to outcome, thereby its `Supervised Learning`.\n",
    "\n",
    "Its always advisable to start learning ML from Supervised ML , as its easier and quick to understand the concepts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "jgCQkQ1dLZLx",
    "outputId": "d7dbf3ce-26dc-46ef-f6cd-1e3bd8446d50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OverallGrade Obedient  ResearchScore  ProjectScore\n",
      "0            A        Y             90            85\n",
      "1            C        N             85            51\n",
      "2            F        N             10            17\n",
      "3            B        Y             75            71\n",
      "4            E        N             20            30\n",
      "5            A        Y             92            79\n",
      "6            B        Y             60            59\n",
      "7            C        Y             75            33\n",
      "----------------\n",
      "  Recommend\n",
      "0       Yes\n",
      "1       Yes\n",
      "2        No\n",
      "3        No\n",
      "4        No\n",
      "5       Yes\n",
      "6        No\n",
      "7        No\n"
     ]
    }
   ],
   "source": [
    "#--get features and corresponding outcomes\n",
    "feature_names = ['OverallGrade', 'Obedient', 'ResearchScore', 'ProjectScore']\n",
    "training_features = df[feature_names]\n",
    "\n",
    "outcome_name = ['Recommend']\n",
    "outcome_labels = df[outcome_name]\n",
    "\n",
    "print(training_features)\n",
    "print(\"----------------\")\n",
    "print(outcome_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ay_qoYrbhDc7"
   },
   "source": [
    "> <font color ='green'> <b> I am sure you have understood that `Features` are what we want to observe. \n",
    "\n",
    "> `Labels` are what we want to predict.</b> </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xQpslwEYkSuO"
   },
   "source": [
    "Now that we have extracted our initial available features from the data and their corresponding outcome labels, let’s separate out our available features based on their type (**`numerical`** and **`categorical`**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hd8RdHaok2Wx"
   },
   "outputs": [],
   "source": [
    "#--list down features based on type\n",
    "\n",
    "numeric_feature_names = ['ResearchScore', 'ProjectScore']\n",
    "\n",
    "categoricial_feature_names = ['OverallGrade', 'Obedient'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lSSYM65EvCEh"
   },
   "source": [
    "We will now use a `standard scalar` from `scikit-learn` to **scale** or **normalize** our two numeric scorebased attributes using the following code.\n",
    "\n",
    "`Note 1 :` **Feature Scaling** is a technique to standardize the independent features present in the data in a fixed range. It is performed during the data pre-processing.\n",
    "\n",
    "*For example , if you have `youtube_Video_counts` dataset. Some videos have very small count say 50 and some very high count say 500000. If the ML model is trained using this data, then it would be baised towards video having view_count say 500000. Thereby when we use this model to predict the count of a video it would mostly predict a high value.*\n",
    "\n",
    "`Note 2 :` Their are three types of Scaling techniques or Algo's : namely **Standard Scalar**, **Min-Max Scalar** and **Robust Scalar**.\n",
    "\n",
    "`Note 3 :` All the scaling algo's are defined in **sklearn.preprocessing** library. \n",
    "\n",
    "`Note 4 :` You would learn about each Scaling technique in a later NB. Have patience.  And Yes : **Scaling** and **Normalization** mean the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "BqjBfpEFzGe-",
    "outputId": "271d349e-66c3-472c-8b18-91202c082871"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  OverallGrade Obedient  ResearchScore  ProjectScore\n",
      "0            A        Y       0.899583      1.376650\n",
      "1            C        N       0.730648     -0.091777\n",
      "2            F        N      -1.803390     -1.560203\n",
      "3            B        Y       0.392776      0.772004\n",
      "4            E        N      -1.465519     -0.998746\n",
      "5            A        Y       0.967158      1.117516\n",
      "6            B        Y      -0.114032      0.253735\n",
      "7            C        Y       0.392776     -0.869179\n"
     ]
    }
   ],
   "source": [
    "# to suppress any unwanted warnings\n",
    "#--turn of warning messages\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "#--scale or normalize our two numeric score-based attributes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()   # we are making the object of StandardScaler\n",
    "\n",
    "# fit scaler on numeric features\n",
    "ss.fit(training_features[numeric_feature_names])  \n",
    "# fit method learns the range of the data, find mean and std_dev\n",
    "\n",
    "# scale numeric features now\n",
    "training_features[numeric_feature_names] = ss.transform(training_features[numeric_feature_names]) \n",
    "# transform method transforms the data. See the o/p. You would see a much reduced range.  \n",
    "\n",
    "# view updated feature-set\n",
    "print(training_features)\n",
    "\n",
    "## Rule for scaling \n",
    "## 1. SS can be applied in almost all cases\n",
    "## 2. If data has outliers then make sure u don't use MMS\n",
    "## 3. If data has outliers then prefer Robust Scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R-EEOsur1ZUC"
   },
   "source": [
    "<b><font color='red'> Did u notice ? </font></b> <br>\n",
    "`Before Transformation` the range of ResearchScore was 10 to 92. <br>\n",
    "`After Transformation` the range of ResearchScore is -1.803390 to 0.967158.  So I am sure you understood that the least value 10 got scaled to -1.803390 and max value 92 got scaled to 0.967158. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GBakggyE4y_N"
   },
   "source": [
    "Now that we have successfully scaled our numeric features, let’s handle our categorical features and carry out the necessary feature engineering. Here we would convert the **`Categorical Data`** into **`Numeric values`**. <font color='green'> Because the ML model do not understand String data. It only understands Numeric inputs. </font>\n",
    "\n",
    "There are many ways to do Feature Engineering over the **`Categorical Data`**. Here we would use; one of the most popular technique **One Hot encoding**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "2EMXkVXV4xO2",
    "outputId": "a9be31b9-77c4-4447-fa26-f3dac59e2b71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResearchScore  ProjectScore  OverallGrade_A  OverallGrade_B  \\\n",
      "0       0.899583      1.376650               1               0   \n",
      "1       0.730648     -0.091777               0               0   \n",
      "2      -1.803390     -1.560203               0               0   \n",
      "3       0.392776      0.772004               0               1   \n",
      "4      -1.465519     -0.998746               0               0   \n",
      "5       0.967158      1.117516               1               0   \n",
      "6      -0.114032      0.253735               0               1   \n",
      "7       0.392776     -0.869179               0               0   \n",
      "\n",
      "   OverallGrade_C  OverallGrade_E  OverallGrade_F  Obedient_N  Obedient_Y  \n",
      "0               0               0               0           0           1  \n",
      "1               1               0               0           1           0  \n",
      "2               0               0               1           1           0  \n",
      "3               0               0               0           0           1  \n",
      "4               0               1               0           1           0  \n",
      "5               0               0               0           0           1  \n",
      "6               0               0               0           0           1  \n",
      "7               1               0               0           0           1  \n"
     ]
    }
   ],
   "source": [
    "#--Engineering Categorical Features\n",
    "training_features = pd.get_dummies(training_features, columns=categoricial_feature_names)\n",
    "\n",
    "# view new engineering features, where the categorical features are coded as binary\n",
    "print(training_features)\n",
    "\n",
    "# We have converted our categoricial data into numeric. \n",
    "# or we can say we have done feature engineering over categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "J7i0iUAZMZ27",
    "outputId": "8839072e-414f-4dce-e104-209bc2595211"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Obedient_Y', 'Obedient_N', 'OverallGrade_E', 'OverallGrade_F', 'OverallGrade_B', 'OverallGrade_C', 'OverallGrade_A']\n"
     ]
    }
   ],
   "source": [
    "#--get list of new categorical features\n",
    "categorical_engineered_features = list(set(training_features.columns) \n",
    "                                       - set(numeric_feature_names))\n",
    "\n",
    "print(categorical_engineered_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gz9O0t1kMlZy"
   },
   "source": [
    "**`Step 4 : Modeling`**<br>\n",
    "We will now build a simple classification (supervised) model based on our feature set by using the logistic regression algorithm. The following code depicts how to build the supervised model.\n",
    "\n",
    "\n",
    "**Wait** before moving ahead , I am assuming that you are very clear with the **difference** of **Supervised & Unsupervised ML**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B5myM355NRg9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression  \n",
    "# importing the class. \n",
    "# LogisticRegression is best suited for binary classification\n",
    "\n",
    "import numpy as np\n",
    "import warnings; warnings.simplefilter('ignore')  \n",
    "\n",
    "# make the model or object\n",
    "lr = LogisticRegression()  # making object of the LogisticRegression class.\n",
    "\n",
    "#--fit the model\n",
    "model = lr.fit(training_features, outcome_labels['Recommend'])\n",
    "# np.array() converts from dataframe to numeric array\n",
    "# well here we are giving 2 i/ps : features and Labels to train the ML model on what i/ps produce what o/ps.\n",
    "# so the model learns the relationship. Hence we say its got trained. \n",
    "# As we gave i/p features and o/p Labels both; thereby its called Supervised Learning \n",
    "\n",
    "\n",
    "# model is ready, it can used to predict on some real data. \n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "TjET-8evO-oY",
    "outputId": "5cb52cdf-5d23-441e-a8f7-d36c58ec8683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name OverallGrade Obedient  ResearchScore  ProjectScore\n",
      "0  Ninad            F        N             10            20\n",
      "1  Alxis            B        Y             78            80\n",
      "2   Faiz            C        N             69            70\n",
      "3  Sejal            A        Y             98            88\n",
      "4  Vijan            E        N             28            30\n"
     ]
    }
   ],
   "source": [
    "# ok, now i am giving you some real student data, \n",
    "# who want to know whether they would be given Research Grant or not ?\n",
    "\n",
    "new_data = pd.DataFrame([{'Name': 'Ninad', 'OverallGrade': 'F', 'Obedient': 'N', 'ResearchScore': 10, 'ProjectScore': 20},\n",
    "                  {'Name': 'Alxis', 'OverallGrade': 'B', 'Obedient': 'Y', 'ResearchScore': 78, 'ProjectScore': 80}, \n",
    "                  {'Name': 'Faiz', 'OverallGrade': 'C', 'Obedient': 'N', 'ResearchScore': 69, 'ProjectScore': 70}, \n",
    "                  {'Name': 'Sejal', 'OverallGrade': 'A', 'Obedient': 'Y', 'ResearchScore': 98, 'ProjectScore': 88},\n",
    "                  {'Name': 'Vijan', 'OverallGrade': 'E', 'Obedient': 'N', 'ResearchScore': 28, 'ProjectScore': 30}])\n",
    "\n",
    "print(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "9o1PRlkARTMu",
    "outputId": "8b2ac88a-c97b-4518-83d2-ac200af074c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ResearchScore  ProjectScore  OverallGrade_A  OverallGrade_B  \\\n",
      "0      -1.803390     -1.430636               0               0   \n",
      "1       0.494137      1.160705               0               1   \n",
      "2       0.190053      0.728815               0               0   \n",
      "3       1.169881      1.506217               1               0   \n",
      "4      -1.195221     -0.998746               0               0   \n",
      "\n",
      "   OverallGrade_C  OverallGrade_E  OverallGrade_F  Obedient_N  Obedient_Y  \n",
      "0               0               0               1           1           0  \n",
      "1               0               0               0           0           1  \n",
      "2               1               0               0           1           0  \n",
      "3               0               0               0           0           1  \n",
      "4               0               1               0           1           0  \n",
      "-----------------------------\n",
      "Index(['ResearchScore', 'ProjectScore', 'OverallGrade_A', 'OverallGrade_B',\n",
      "       'OverallGrade_C', 'OverallGrade_E', 'OverallGrade_F', 'Obedient_N',\n",
      "       'Obedient_Y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# w.r.t new data\n",
    "# We will now carry out the tasks relevant to \n",
    "# data preparation—feature extraction, engineering, and scaling \n",
    "# in the following code snippet.  Same as what we did over training data.\n",
    "\n",
    "#--data preparation\n",
    "prediction_features = new_data[feature_names]\n",
    "\n",
    "#--scaling by using standardScalar object -> ss\n",
    "prediction_features[numeric_feature_names] = ss.transform(prediction_features[numeric_feature_names])\n",
    "\n",
    "#--engineering categorical variables -> using One Hot Encoding\n",
    "prediction_features = pd.get_dummies(prediction_features, \n",
    "                                     columns=categoricial_feature_names)\n",
    "\n",
    "#--view feature set\n",
    "print(prediction_features)\n",
    "print(\"-----------------------------\")\n",
    "print(prediction_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhqIc9o0Sz_5"
   },
   "source": [
    "**Important :** We are safe, as the no. of columns in the training_features and prediction_features <font color='green'><b>are same</b></font>.\n",
    "\n",
    "**Don't worry**, *we will later come across cases where the test data or real time data on which we wish to do predictions , does not have same no. of features. In such cases we will have to add dummy feature columns. Will talk and code on this some time later.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "QNJrzaHWUETp",
    "outputId": "81da2c5f-9174-424a-856d-af0bf2602ae1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name OverallGrade Obedient  ResearchScore  ProjectScore Recommend\n",
      "0  Ninad            F        N             10            20        No\n",
      "1  Alxis            B        Y             78            80        No\n",
      "2   Faiz            C        N             69            70       Yes\n",
      "3  Sejal            A        Y             98            88       Yes\n",
      "4  Vijan            E        N             28            30        No\n"
     ]
    }
   ],
   "source": [
    "# We have our complete feature set ready for all the new students. \n",
    "# Let’s put our model to the test and get the predictions \n",
    "# with regard to grant recommendations!\n",
    "\n",
    "predictions = model.predict(prediction_features)\n",
    "\n",
    "##--display results\n",
    "new_data['Recommend'] = predictions\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fjli9wbIUxq-"
   },
   "source": [
    "<font color='green'><b>Wow !!! </b></font>\n",
    "\n",
    "You have done a great Job in this NB.\n",
    "\n",
    "Let me summarise for you : \n",
    "> You understood that applying ML to some data is a <font color='green'> well defined process called ML pipeline </font>. \n",
    "\n",
    "> **You first load data**, Like we loaded it from a .csv file. Although we could load from other sources like DataBase, web-Scrap a website , from json files or read from PDF or word doc file.\n",
    "\n",
    "> You then did **required** Pre-processing like Cleaning the data, **Scaling numeric data** and **Feature engineering on Categorical data**. Like we used <font color='green'>  Standard Scaler over Numeric data and One Hot Encoding over Categorical data.</font>\n",
    "\n",
    "> You then loaded the required class, like we loaded (i.e imported) LogisticRegression class.  <br>\n",
    "*`from sklearn.linear_model import LogisticRegression`* <br>\n",
    "Remember we would use **sklearn library** a lot. Its the most used and most popular Library in Machine learning.\n",
    "\n",
    "> Then I gave some dummy student data. You smartly applied your ML model over it to classify who would get **`Research Grant and who would not ?`**\n",
    "\n",
    "<h3><font color='green'>Trust me you are going Great !! </font></h3>\n",
    "\n",
    "<b>You can connect with your Simplilearn SME</b>: \n",
    "<h3> Mr. Rocky Jagtiani, <a href =\"https://www.linkedin.com/in/rocky-jagtiani-3b390649/\" />  Here</a> </b>.</h3>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_ML Pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
